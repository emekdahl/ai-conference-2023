#vector #genai #ai #rockset 

# Six Hard Parts of Vector-Powered Applications

## AI Summary

The notes discuss the complexities and challenges of working with vector databases, particularly in the context of managing unstructured data and maintaining performance.

#### Key Points:

- **Vector Search vs. Vector Database**: Vector databases solve a broader range of problems than just vector search. Using libraries like HNSW and FAISS is fine for prototyping but becomes complex when moving to production.
    
- **Incremental Indexing**: Adding new vectors to an existing index can make it outdated. Strategies include embracing suboptimal performance, batch indexing, or improving core algorithms.
    
- **Data Latency**: Understanding your tolerance for data latency is crucial, especially when dealing with real-time requirements. Streaming vectors require different architectures than batch processing.
    
- **Metadata Filtering**: Filtering based on metadata is challenging because pre-computed indexes don't include filtered data. Strategies include post-filtering, pre-filtering, and single-stage filtering, the latter being the most modern approach.
    
- **Filter Selectivity Estimation**: Cost optimization for running filters is a well-studied problem in relational databases but still an evolving area in vector databases.
    
- **Resource Constraints**: Balancing resource use between ingestion/indexing and queries is challenging, especially as workloads change unpredictably.
    
- **Rocket Solutions**: Discusses specific solutions using Rocket and FAISS to tackle vector database issues. Rocket uses RocksDB as the storage engine and offers performance optimizations like separating storage from compute.
    

The notes emphasize the need for a deep understanding of the intricacies involved in vector databases, from indexing to latency to resource management, for effective implementation and scaling.

## Notes

## Assumptions

- given unstructured data
- project / embed them into a vector database


## Vector search != vector database

- vector databases solve many, many more problems than just vector problems
- beware the homegrown "vector search infra"
	- you can download HNSW, FAISS for prototyping
	- production-izing them will result in accidentally inventing a database
		- atomic

## Incremental Indexing of Vectors

- What happens when I add new vectors?
- index is increasingly out of date
- naively updating is inefficient and suboptimal
- for example, in a balanced binary search tree where values are incrementally added, the performance will degrade over time

### Strategies

- embrace suboptimal performance associated with incremental updates
- batch index
	- multiple indexes, making new ones as you go
	- occasionally compact them
- improve the core algorithms
	- lessen the penalty for incremental updates
	- then publish it

## Data Latency

- how long after you "create" a vector do you need it to be searchable in your index?
	- for example, data warehouses typically have a vacuum operation
- understand your tolerance for data latency
	- both for the vector and its metadata
	- for example, movie recommendations 5 minutes stale is probably acceptable, whereas for e-commerce, the recent search results are very relevant and important
- Streaming vectors requires a different architecture than batch
- Beware propagation delays with replicated storage


## Metadata Filtering

- the **WHERE** clause
- show me all the images like this one
	- ...that were uploaded in the last 10 minutes
- show me all the streams I might like
	- but only if the user is online right now
- show me products I might like
	- but only if they are in stock

### Why is it Hard?

- index is pre-computed
	- you don't have an index of the __filtered__ data
- many choices
	- post-filter - over fetch vectors, then filter
	- pre-filter - filter first, then scan
	- single stage filter - merge the filtering and ANN search algorithms
		- more modern, golden approach
		- choose a database where the vector index can be concurrently executed alongside other filters in the database (actually get the nearest neighbors)

## Filter Selectivity Estimation

- metadata filters are pretty abstract
- if you're building an actual application at scale, the filter is based on user, context, and application data, which is hard to predict in advance
- running filters fast is a very well-studied and hard problem in database engineering (a.k.a. cost optimization)
- cost-based query optimizer
- while this is a problem that's been extensively worked on in relational databases, vector databases are still working on these hard problems

## Resources are Finite

- whether on-prem or in the cloud, you still have to wait 
- contending between ingestion and indexing vs. search queries
	- these change throughout the day between customers and workloads and are hard to predict
- simple case
	- 2-way contention between indexing and queries
- harder cases
	- multiple ingestion (batch v streaming) workloads
	- multiple applications' query workloads
	- single application's queries as qps spikes
	- background jobs (e.g., index build) and everything
		- if you are doing a periodic complete index rebuild, vectors are very memory intensive, especially if using a graph-based index

## Rocket Solutions to Vector DB Hard Problems

- Create FAISS inverted file index (IVF) and store centroid identifiers in memory
	- with each new record, compute and store centroid and residual
- at query time, rockset's query optimizer as FAISS for the closet centroids to the target embedding
	- 3 is a good tradeoff between query and execution
- FAISS returns three centroids. Rockset now rewrites the query
- rockset's execution engine uses the inverted index to perform single-stage filtering

## Rockset
- uses rocksdb as the storage engine
	- LSM engine, write optimized
	- shred documents into KV pairs
- rocket is mutable at the individual field level
- new records queryable within ~100ms
- inline generation of centroids and residuals with FAISS
- performance optimization
	- separate storage from compute
	- separated compute from compute so multiple computers can talk to storage
	- isolated query workloads
	- you are in control of how you handle resource contention


